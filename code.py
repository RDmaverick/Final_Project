# -*- coding: utf-8 -*-
"""

Automatically generated by Colab.





**Predicting Diabetes**

The goal of this project is to analyze medical data and to build predictive models to predict type 2 diabetes basis the provided health indicators in the dataset. Due to the imbalanced nature of the dataset, we will also explore techniques to address this issue, such as stratified splits, adjusting class weights during model training and using ensemble methods.

**Source of the dataset**

Kaggle Link: [Diabetes Health Indicators Dataset](https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset/data)

We have specifically used the data file titled "diabetes_binary_health_indicators_BRFSS2015.csv", which is a cleaned and consolidated dataset created (by the author [here](https://www.kaggle.com/code/alexteboul/diabetes-health-indicators-dataset-notebook/notebook)) from the [original BRFSS 2015 dataset](https://www.kaggle.com/datasets/cdc/behavioral-risk-factor-surveillance-system) on Kaggle.

The target variable has 2 classes (0 for no diabetes, 1 for prediabetes or diabetes). Prediabetes and Diabetes are clubbed together in one category because if a doctor tells you that you are prediabetic, its an indication of diabetes risk, and ultimately we are interested in risk. There are 21 features.

**About the BRFSS Data (in general)**


The Behavioral Risk Factor Surveillance System (BRFSS) is a health-related telephonic survey thats collected annually by the CDC from over 400k Americans on health-related behaviors, chronic health conditions, and the use of preventative services. The original dataset contains about 441,455 records and has 330 features. The features are either questions directly asked of participants, or calculated variables based on individual participant responses.

### **About the dataset/Data Dictionary**

| S.No. | Feature | Type | Feature Description | Values |
| --- | --- | --- | --- | --- |
| 1 | Diabetes_binary | Categorical | The target variable. Indicates whether the respondent has prediabetes/diabetes or not. | 0 = no diabetes, 1 = prediabetes or diabetes |
| 2 | HighBP | Categorical | Adults who have been told they have high blood pressure by a doctor, nurse, or other health professional | 0 = no, 1 = yes |
| 3 | HighChol | Categorical | Have you ever been told by a doctor, nurse or other health professional that your blood cholesterol is high? | 0 = no, 1 = yes |
| 4 | CholCheck | Categorical | Cholesterol check within past five years | 0 = no, 1 = yes |
| 5 | BMI | Numerical | Body Mass Index | Positive Integer between 12 and 98 |
| 6 | Smoker | Categorical | Have you smoked at least 100 cigarettes in your entire life? | 0 = no, 1 = yes |
| 7 | Stroke | Categorical | Have you ever had a stroke? | 0 = no, 1 = yes |
| 8 | HeartDiseaseorAttack | Categorical | Have you ever had coronary heart disease (CHD) or myocardial infarction (MI) | 0 = no, 1 = yes |
| 9 | PhysActivity | Categorical | Have you done any physical activity or exercise during the past 30 days other than your regular job | 0 = no, 1 = yes |
| 10 | Fruits | Categorical | Do you consume fruit 1 or more times per day? | 0 = no, 1 = yes |
| 11 | Veggies | Categorical | Do you consume vegetables 1 or more times per day? | 0 = no, 1 = yes |
| 12 | HvyAlcoholConsump | Categorical | Are you a heavy drinker? (Heavy meaning adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) | 0 = no, 1 = yes |
| 13 | AnyHealthcare | Categorical | Do you have any kind of health care coverage, including health insurance, prepaid plans such as HMOs, or government plans such as Medicare, or Indian Health Service? | 0 = no, 1 = yes |
| 14 | NoDocbcCost | Categorical | Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? | 0 = no, 1 = yes |
| 15 | GenHlth | Categorical | What would you say that in general your health is? (between 1 to 5) | 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor |
| 16 | MentHlth | Numerical | Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how many days during the past 30 days was your mental health not good? | Integer between 0 and 30 |
| 17 | PhysHlth | Numerical | Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 days was your physical health not good? | Integer between 0 and 30 |
| 18 | DiffWalk | Categorical | Do you have serious difficulty walking or climbing stairs? | 0 = no, 1 = yes |
| 19 | Sex | Categorical | Gender of the respondent | 0 = female, 1 = male |
| 20 | Age | Ordinal | Age category of the respondent | 1 = 18-24 years, 2 = 25-29 years, 3 = 30-34 years, 4 = 35-39 years, 5 = 40-44 years, 6 = 45-49 years, 7 = 50-54 years, 8 = 55-59 years, 9 = 60-64 years, 10 = 65-69 years, 11 = 70-74 years, 12 = 75-79 years, 13 = 80 or older
| 21 | Education | Ordinal | What is the highest grade or year of school you completed? | 1 = never attended school/only kindergarten, 2 = Grade 1 to 8 (Elementary) , 3 = Grades 9 to 11 (Some High School), 4 = Grade 12 or GED (High School Graduate), 5 = College 1 year to 3 years (Some college or technical school), 6 = 4 year College or more (College Graduate)  |
| 22 | Income | Ordinal | Annual household income of the respondent (in USD) | 1 = less than 10000, 2 = 10000 to 15000, 3 = 15000 to 20000, 4 = 20000 to 25000, 5 = 25000 to 35000, 6 = 35000 to 50000, 7 = 50000 to 75000, 8 = 75000 or more |
"""

# IMPORTS
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
import warnings
# To ignore all warningsssa
warnings.filterwarnings("ignore")

from scipy import stats
import time

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, make_scorer, roc_auc_score, roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

# TO UPLOAD DATA FILE IN COLAB
from google.colab import files
uploaded = files.upload()

# Load the dataset
diabetes_data = pd.read_csv('diabetes_binary_health_indicators_BRFSS2015.csv')
diabetes_data.head()

"""### **Data Cleaning**"""

# Dataset shape
print("Shape of the data:", diabetes_data.shape)

## Checking datatypes
print(diabetes_data.info())

# Checking for missing values. It seems we don't have missing data. As mentioned above, this is a relatively clean dataset.
diabetes_data.isnull().sum()

# Checking for Duplicates
print("Duplicate Observations", diabetes_data[diabetes_data.duplicated()].shape[0])

"""We have 24206 "duplicate" observations/respondents (9.5%). It could very well be the case that a large number of people surveyed fall into the same categories, we can't really say. We have decided to remove these duplicates since they might not add that much value to the model and we already have a lot of data."""

# Dropping Duplicates
diabetes_data.drop_duplicates(inplace = True)

# Dataset shape after dropping duplicates
print("Shape of data after dropping duplicates:", diabetes_data.shape)

"""### **Exploratory Data Analysis**"""

pd.set_option('display.max_columns', None)
diabetes_data.describe()

pd.reset_option('all')

# Checking the distribution of the target variable. We can see that its imbalanced (which sounds logical)

plt.pie(diabetes_data['Diabetes_binary'].value_counts(),
        labels = ['0 / Non-Diabetic', '1 / Pre-diabetic or Diabetic'],
        autopct = '%1.2f%%',
        startangle = 90)
plt.title('Distribution of the target variable: Diabetes_binary')
plt.show()

"""Lets get a visual understanding of the relationship between individual features and the target. The following plots will offer us insights into the distribution of diabetes cases across different categories for each feature, helping to identify patterns and potential associations.

We will plot a countplot showing the count of diabetes cases for each category of the variable. Additionally, we have also overlaid a pointplot, which represents the average percentage of diabetic cases for each category of the variable.

Note: We have first plotted for all features **except** BMI, MentHlth and PhysHlth since they have a lot of categories.
"""

features = ['HighBP', 'HighChol', 'CholCheck', 'Stroke', 'HeartDiseaseorAttack',
            'Smoker', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump',
            'AnyHealthcare', 'NoDocbcCost',
            'GenHlth', 'DiffWalk',
            'Age', 'Sex', 'Education', 'Income']

fig, axes = plt.subplots(6, 3, figsize=(18, 30))
fig.suptitle("Relationship b/w Individual features and the target")

for i, var in enumerate(features[:22]):  #Iterate through the features to create a set of subplots. For each feature, it plots a countplot (with diabetes cases differentiated by hue) and overlays a pointplot representing the percentage of diabetic cases.
    ax = axes[i // 3][i % 3]

    sns.countplot(x=var, hue="Diabetes_binary", data=diabetes_data, ax=ax)
    ax.set(xlabel=var, ylabel="Count", title=f"Count of Diabetes cases by {var}")

    ax2 = ax.twinx() # The twinx() method is used to create a secondary y-axis for the pointplot
    sns.pointplot(x=var, y="Diabetes_binary", data=diabetes_data.groupby(var).mean().reset_index(),
                  color= "black", markers='x', scale=0.6, ax=ax2)

    ax2.set(ylim=[0, 1], ylabel="% Diabetic")

plt.tight_layout(rect=[0, 0, 1, 0.96]) #Adjust the layout for better visualization and display the set of subplots.
plt.show()

"""**Some Key Observations**

1. HighBP: Having hypertension/HighBP appears to increase the risk of getting type 2 diabetes/prediabetes (and vice-versa)
2. HighChol: Having high cholestrol appears to increase the risk of getting type 2 diabetes/prediabetes (and vice-versa)
3. Stroke: People who have type 2 diabetes/prediabetes appear to be more prone to having a stroke compared to people who do not have diabetes.
4. HeartDiseaseorAttack: People who have type 2 diabetes/prediabetes appear to be more prone to have a Heart Disease or a Heart Attack as compared to people who do not have diabetes.
5. Smoker: As per the data, smoking slightly increases the risk of diabetes.
6. PhysActivity, Fruits, Veggies: The proportion of non-diabetic people who are physically active or who consume fruit 1 or more times per day or who consume vegetables 1 or more times per day is slightly higher than the proportion of non-diabetic people who do not do these things. It indicates that doing these things are associated with a reduced risk of diabetes/prediabetes.
7. GenHlth: Individuals with diabetes/prediabetes perceive a significantly lower level of well-being compared to those without the condition.
8. DiffWalk: As per the data, people with Diabetes/Prediabetes have a significant difficulty walking or climbing stairs as compared to people without the condition.
9. Age: The data indicates that as people get older, their risk of getting type 2 diabetes/prediabetes tends to increase.
10. Sex: Males show a slightly higher likelihood of having type 2 diabetes/prediabetes compared to females
11. Education, Income: Individuals with higher education levels and income are discovered to be at a lower risk of developing type 2 diabetes/prediabetes.

Plotting the same graphs for BMI, MentHlth, PhysHlth
"""

for feature in ['BMI', 'MentHlth', 'PhysHlth']:
  if (feature == 'BMI'):
    fig, ax = plt.subplots(figsize=(40, 8))
  else:
    fig, ax = plt.subplots(figsize=(20, 8))
  ax.set_title(f"Count of Diabetes cases by {feature}")
  ax.set_xlabel(feature)
  ax.set_ylabel("Count")

  sns.countplot(x=feature, hue="Diabetes_binary", data=diabetes_data, ax=ax)

  ax2 = ax.twinx()
  sns.pointplot(x=feature, y="Diabetes_binary", data=diabetes_data.groupby(feature).mean().reset_index(),
                color='red', markers='x', scale=0.6, ax=ax2)

  ax2.set(ylim=[0, 1], ylabel="% Diabetic")
  plt.show()

"""**Observations**

1. For BMI > 25 and BMI > 30, the overweight and obese categories, the percentage of people with diabetes is constantly increasing.
"""

# Correlation between features
fig, ax = plt.subplots(figsize=(10, 7))
heatmap = sns.heatmap(diabetes_data.corr(), cmap = 'seismic', mask = np.triu(np.ones_like(diabetes_data.corr(), dtype=bool)), annot=False, vmin=-1, vmax=1)
heatmap.set_title('Correlation Heatmap');

"""**Observations**
1. Strong Positive Correlation: Between PhysHlth and GenHlth, DiffWalk and GenHlth, DiffWalk and PhysHlth, Income and Education
2. Strong Negative Correlation: Between Income and GenHlth (Remember GenHlth is encoded between 1 to 5 where 1 is excellent and 5 is poor)
"""

# Correlation with target
correlation = diabetes_data.drop('Diabetes_binary', axis=1).corrwith(diabetes_data['Diabetes_binary'])
correlation.sort_values().plot(kind='bar', grid=True, figsize=(14, 6), title="Correlation with Diabetes_binary", color="blue")
plt.show()

"""**Observations**

1. Features that have a very weak correlation with Diabetes_binary: Veggies, Fruits, NoDocbccost, AnyHealthcare, and Sex
2. Features that are more correlated with Diabetes_binary: GenHlth, HighBP, DiffWalk, BMI, HighChol, Age, HeartDiseaseorAttack, PhysHlth, Stroke, PhysActivity, Education, Income

### **Hypothesis Testing**

Individuals with a combination of healthier dietary habits (once a day consumption of fruits and vegetables), non-smoking behaviour, non-heavy alcohol consumption, and regular physical activity are hypothesised to have a lower likelihood of having diabetes or prediabetes.

Initially we will perform chi-square test to calculate the p-values of individual attributes and then use Bonferroni's method to correct the significance leve of the p-values to check if the are statistically significant when combined.

H0 - There is no significant relationship between combination of healthier habit attributes and diabetes target variable.

H1 - There is significant relationship between combination of healthier habit attributes and diabetes target variable.
"""

# Define attributes of interest
attributes = ["Smoker", "PhysActivity", "Fruits", "Veggies", "HvyAlcoholConsump"]

# Conduct chi-square test for each attribute
pvals = []
for attribute in attributes:
    _, pval, _, _ = stats.chi2_contingency(pd.crosstab(diabetes_data[attribute], diabetes_data["Diabetes_binary"]))
    pvals.append(pval)

# Apply Bonferroni correction
alpha = 0.05  # significance level
adjusted_alpha = alpha / len(attributes)  # adjusted alpha for each test

for i, attribute in enumerate(attributes):
    if pvals[i] < adjusted_alpha:
        print(f"Reject null hypothesis. There is a statistically significant relationship between {attribute} and diabetes (adjusted p-value: {pvals[i]})")
    else:
        print(f"Fail to reject null hypothesis. No statistically significant relationship between {attribute} and diabetes (adjusted p-value: {pvals[i]})")

"""The combined p-value is very small (6.906569461487025e-219), significantly lower than the significance level of 0.05.
This rejects the null hypothesis. At least one of the attributes has a statistically significant relationship with diabetes.
Now that we know at least one of the attributes are significant, we can build a simple logistic model to figure out the direction of influence each has on the target varible.
"""

# Instantiate and fit the logistic regression model
model = LogisticRegression()
model.fit(diabetes_data[attributes], diabetes_data["Diabetes_binary"])

predicted_labels = model.predict(diabetes_data[attributes])

accuracy = accuracy_score(diabetes_data["Diabetes_binary"], predicted_labels)
print(f"Model accuracy: {accuracy * 100:.2f}%")

print(classification_report(diabetes_data["Diabetes_binary"], predicted_labels))

# Extract and interpret coefficients
coefficients = model.coef_[0]
for i, attribute in enumerate(attributes):
    if coefficients[i] > 0:
        print(f"{attribute}: increases the odds of diabetes by a factor of {round(np.exp(coefficients[i]))}.")
        print(coefficients[i])
    else:
        print(f"{attribute}: decreases the odds of diabetes by a factor of {round(np.exp(-coefficients[i]))}.")
        print(coefficients[i])

"""**Individual Attribute Coefficients**

Smoker: A positive coefficient indicates that being a smoker increases the odds of developing diabetes by a factor of 1.

PhysActivity: A negative coefficient indicates that engaging in physical activity decreases the odds of developing diabetes by a factor of 2.

Fruits: A negative coefficient indicates that consuming fruits decreases the odds of developing diabetes by a factor of 1.

Veggies: A negative coefficient indicates that consuming vegetables decreases the odds of developing diabetes by a factor of 1.

HvyAlcoholConsump: A negative coefficient indicates that heavy alcohol consumption decreases the odds of developing diabetes by a factor of 4.

**Overall Interpretation**

These results suggest a statistically significant association between at least one of the attributes and diabetes. The logistic regression model provides further insights into the direction and magnitude of these associations. Specific habits like smoking increase the risk of diabetes, while healthy habits like physical activity, fruit and vegetable consumption, and reduced heavy alcohol consumption decrease the risk.

### **Data Modeling**
"""

X = diabetes_data.drop("Diabetes_binary", axis=1)  # Features
y = diabetes_data["Diabetes_binary"]  # Target variable

"""### Logistic Regression ###

"""

X_train_valid, X_test, y_train_valid, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = 862)

thresholds = np.linspace(0, 1, 11) # Setting up a range of 10 threshold values
thresholds = np.delete(thresholds,[10])

ROC_AUC_List = []
start_time_lr = time.time()

for ind, threshold in enumerate(thresholds): # Loop over each candidate value of thresholds
    # StratifiedKFold
    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 862) #Instantiating the fold

    temp_ROC_AUC = [] # To store the current threshold's AUC-score for the current fold's data

    for train_index, valid_index in kfold.split(X_train_valid, y_train_valid): # Splitting into Training and Validation set
        X_train, y_train = X_train_valid.iloc[train_index], y_train_valid.iloc[train_index] # Training set
        X_valid, y_valid = X_train_valid.iloc[valid_index], y_train_valid.iloc[valid_index] # Validation set

        #Scale the data
        scaler = StandardScaler()
        scaler.fit(X_train)
        X_train = pd.DataFrame(scaler.transform(X_train))
        X_valid = pd.DataFrame(scaler.transform(X_valid))
        X_train.columns = X.columns.values
        X_valid.columns = X.columns.values

        C_values = [0.1, 0.3, 0.5, 0.75, 1]

        #Perform Logistic Regression fitting on the training data with elasticnet penalty, using saga solver and max iterations of 10000
        ##elasticnet considers both L1 and L2 penalties
        for C in C_values:
            lr = LogisticRegression(penalty ='elasticnet', l1_ratio=0.5, C=C, solver = 'saga', max_iter = 10000 , random_state=862)
            lr.fit(X_train, y_train)

            y_pred_threshold = np.where(lr.predict_proba(X_valid)[:,1] > threshold, 1, 0) # Getting predicted classes of the validation data for a particular threshold

            temp_ROC_AUC.append(roc_auc_score(y_valid, y_pred_threshold))

    ROC_AUC_List.append(np.mean(temp_ROC_AUC)) # Calculate the average ROC AUC score across all 5 folds

end_time_lr=time.time()
elapsed_time_lr=end_time_lr-start_time_lr
print(f"\nTime taken for Logistics Regression: {elapsed_time_lr:.2f} seconds")

# Saving threshold since we will use them later
best_threshold_maximizing_ROC_AUC = thresholds[np.argmax(ROC_AUC_List)]
best_C_maximizing_ROC_AUC = C_values[np.argmax(ROC_AUC_List)]

# Print Maximum F-1 score and its corresponding threshold
print('Logistic Regression with 5-fold CV - Validation Set Maximized ROC AUC score is', max(ROC_AUC_List), 'at a threshold value of', best_threshold_maximizing_ROC_AUC, 'at a C value of', best_C_maximizing_ROC_AUC)

# Again, scaling the  (training+validation) and the testing set
scaler = StandardScaler()
scaler.fit(X_train_valid)
X_train_valid = pd.DataFrame(scaler.transform(X_train_valid))
X_test = pd.DataFrame(scaler.transform(X_test))
X_train_valid.columns = X.columns.values
X_test.columns = X.columns.values

# Refitting the model with the (training + validation) data
lr.fit(X_train_valid, y_train_valid)

y_pred_lg = np.where(lr.predict_proba(X_test)[:,1] > best_threshold_maximizing_ROC_AUC, 1, 0) # Getting predicted classes of the testing data at our tuned threshold value

print("\nModel Evaluation on Test Set (Logistics Regression):")

print("\nBest threshold  (Logistics Regression):", best_threshold_maximizing_ROC_AUC)
print("\nBest C Value:", best_C_maximizing_ROC_AUC)

## Plotting Confusion Matrix
print("\nConfusion Matrix:")
plt.figure(figsize=(4, 3))
sns.heatmap(confusion_matrix(y_test, y_pred_lg), annot=True, fmt="d", cmap="Blues", linewidths=.5, cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Value of Diabetes')
plt.ylabel('True Value of Diabetes')
plt.show()

print("\nClassification Report:")
print(classification_report(y_test, y_pred_lg))

## printing coefficients
coefficients = lr.coef_[0]
print("\nLogistic Regression Coefficients:")
for feature, coef in zip(X.columns, coefficients):
    print(f"{feature}: {coef:.4f}")

# Plot ROC Curve
fpr_lr, tpr_lr, thresholds_lr = roc_curve(y_test, y_pred_lg)
roc_auc_lr = auc(fpr_lr, tpr_lr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr_lr, tpr_lr, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc_lr))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Logistic Regression')
plt.legend(loc='lower right')
plt.show()

"""**Observations**

1. Time Taken for Logistic Regression : 340 seconds

2. AUC is the ability of a classifier to distinguish b/w classes and is used as a summary of the ROC curve. Higher the AUC, the better the performance of the model at distinguishing between the positive and negative classes. Looking at the ROC curve, the score is 0.72 which means 72% of the times, the model is correctly distinguishing between the positive and the negative classes.

3. The hyperparameters when AUC score of the test set is maximized: Threshold = 0.1, C = 0.3

4. F1 score on the minority class Test Set: 0.41

5. Looking at the confusion matrix, we see a high number of false positives

6.  Features such as GenHlth, BMI, HighBP, HighChol, Age have notable positive influences on the prediction of diabetes health indicator. Features such as Smoker, PhysActivity, Fruits, Veggies, and HvyAlcoholConsump have relatively lower influences, with Smoker having almost negligible impact.

**Preparing Data for Random Forest and GBM**
"""

X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y,
                                                    test_size = 0.2,
                                                    stratify = y,
                                                    random_state = 862) ## Statrify to make sure we have balanced Y in both train test data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train1) ## Scaling training set
X_test_scaled = scaler.transform(X_test1) ## Scaling testing set

"""### Random Forest Classifier ###"""

# Random Forest Classifier
rf_classifier = RandomForestClassifier(class_weight = "balanced", random_state=862)

rf_grid = {
    'n_estimators': [200, 300],
    'max_depth': [6, 8, 10],
    'criterion': ['gini', 'entropy']
}

start_time_rf=time.time()
grid_search_rf = GridSearchCV(rf_classifier, rf_grid, cv=5, scoring='roc_auc', n_jobs=-1)
grid_search_rf.fit(X_train_scaled, y_train1)
end_time_rf = time.time()
elapsed_time_rf = end_time_rf - start_time_rf
print(f"\nTime taken for Random Forest: {elapsed_time_rf:.2f} seconds")

y_pred_rf = grid_search_rf.predict(X_test_scaled)

print("\nModel Evaluation on Test Set (Random Forest):")

best_params_rf = grid_search_rf.best_params_
print("\nBest Hyperparameters (Random Forest):", best_params_rf)

print("\nConfusion Matrix:")
plt.figure(figsize=(4, 3))
sns.heatmap(confusion_matrix(y_test1, y_pred_rf), annot=True, fmt="d", cmap="Blues", linewidths=.5, cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Value of Diabetes')
plt.ylabel('True Value of Diabetes')
plt.show()

print("\nClassification Report:")
print(classification_report(y_test1, y_pred_rf))

feature_importance_rf = grid_search_rf.best_estimator_.feature_importances_
print("\nFeature Importance (Random Forest):")
for feature, importance in zip(X.columns, feature_importance_rf):
    print(f"{feature}: {importance:.4f}")

sorted_idx_rf = feature_importance_rf.argsort()
sorted_features_rf = X.columns[sorted_idx_rf]
sorted_importance_rf = feature_importance_rf[sorted_idx_rf]

plt.figure(figsize=(10, 6))
plt.barh(range(len(sorted_features_rf)), sorted_importance_rf, color='red',align="center")
plt.yticks(range(len(sorted_features_rf)), sorted_features_rf)
plt.xlabel("Feature Importance")
plt.title("Random Forest Feature Importance")
plt.show()

# Calculate predicted probabilities
y_prob_rf = grid_search_rf.predict_proba(X_test_scaled)[:, 1]

# Calculate ROC curve and AUC
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test1, y_prob_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc_rf))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Random Forest')
plt.legend(loc='lower right')
plt.show()

"""**Observations**
1. Time Taken for Random Forest: 952.4 seconds
2. AUC Score 0.81
3. Hyperparameters that maximize AUC score: n_estimators = 300, max_depth = 10, criterion = entropy
4. F1 score for the minority class on test set: 0.45
5. Important Features (Contribution of each feature to the model's predictions): GenHlth, HighBP, BMI, Age, HighChol, DiffWalk
6. Better F1 score as compared to Logistic Regression.
7. **Note** that we have set the parameter **class_weights = balanced**, meaning the classes are weighed inversely proportional to how frequently they appear in the data.

### Gradient Boosting Classifier ###
"""

# Gradient Boosting Classifier
gb_classifier = GradientBoostingClassifier(min_samples_leaf = 5, random_state=862)

gb_grid = {
    'n_estimators': [200, 300],
    'max_depth': [8, 10],
    'learning_rate': [0.01, 0.05]
}
start_time_gb=time.time()
grid_search_gb = GridSearchCV(gb_classifier, gb_grid, cv=5, scoring='roc_auc', n_jobs=-1)
grid_search_gb.fit(X_train_scaled, y_train1)
end_time_gb=time.time()
elapsed_time_gb=end_time_gb-start_time_gb
print(f"\nTime taken for Gradient Boosting: {elapsed_time_gb:.2f} seconds")

y_pred_gb = grid_search_gb.predict(X_test_scaled)

print("\nModel Evaluation on Test Set (Gradient Boosting):")

best_params_gb = grid_search_gb.best_params_
print("\nBest Hyperparameters (Gradient Boosting):", best_params_gb)

print("\nClassification Report:")
print(classification_report(y_test1, y_pred_gb))

print("\nConfusion Matrix:")
plt.figure(figsize=(4, 3))
sns.heatmap(confusion_matrix(y_test1, y_pred_gb), annot=True, fmt="d", cmap="Blues", linewidths=.5, cbar=False)
# Customize plot
plt.title('Confusion Matrix')
plt.xlabel('Predicted Value of Diabetes')
plt.ylabel('True Value of Diabetes')
plt.show()

feature_importance_gb = grid_search_gb.best_estimator_.feature_importances_
print("\nFeature Importance (Gradient Boosting):")
for feature, importance in zip(X.columns, feature_importance_gb):
    print(f"{feature}: {importance:.4f}")

sorted_idx_gb = feature_importance_gb.argsort()
sorted_features_gb = X.columns[sorted_idx_gb]
sorted_importance_gb = feature_importance_gb[sorted_idx_gb]

plt.figure(figsize=(10, 6))
plt.barh(range(len(sorted_features_gb)), sorted_importance_gb,color='lightgreen', align="center")
plt.yticks(range(len(sorted_features_gb)), sorted_features_gb)
plt.xlabel("Feature Importance")
plt.title("Gradient Boosting Feature Importance")
plt.show()

# Calculate predicted probabilities
y_prob_gb = grid_search_gb.predict_proba(X_test_scaled)[:, 1]

# Calculate ROC curve and AUC
fpr_gb, tpr_gb, thresholds_gb = roc_curve(y_test1, y_prob_gb)
roc_auc_gb = auc(fpr_gb, tpr_gb)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr_gb, tpr_gb, color='darkgreen', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc_gb))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Gradient Boosting')
plt.legend(loc='lower right')
plt.show()

"""**Observations**
1. Time Taken for Gradient Boosting: 5771.5 seconds
2. AUC Score 0.81
3. Hyperparameters that maximize AUC score: n_estimators = 300, max_depth = 8, learning rate = 0.01
4. F1 score for the minority class on test set: 0.21
5. Important Features (Contribution of each feature to the model's predictions): HighBP, GenHlth, BMI, Age, HighChol/
6. Lower F1 score as compared to Logistic Regression. (**but there was no parameter like class_weights in GBC**)

### Summary and Conclusions


| Model | AUC ROC Score | F1 Score of Minority Class | Best Hyperparameters | Time Taken (seconds) |
|-------|----------|----------|-----------------------|------------------------|
| Logistic Regression | 0.72 | 0.41 | threshold = 0.1, C = 0.3 | 340.61 |
| Random Forest | 0.81 | 0.45 | 'criterion': 'entropy', 'max_depth': 10, 'n_estimators': 300 | 952.4 |
| Gradient Boosting | 0.81 | 0.21 | 'learning_rate': 0.01, 'max_depth': 8, 'n_estimators': 300 | 5771.46 |



1. **Model Limitations:**
   - The models face challenges in accurately predicting individuals with diabetes, as evidenced by low recall and F1 score for the minoroty class / class 1/Diabetic.
   - The imbalance in class distribution is definitely contributing to the models' biases towards predicting the majority class.

2. **Potential Improvements:**
   - Definitely strategies to address class imbalance, such as oversampling, undersampling, or a combination of both.
   - For the imbalanced dataset we used, maybe trying different evaluation metrics when training the model (such as the f1 score, or the f2 score, which place higher importance on False Negatives, or the Recall) could slightly enhance model performance.
   - Further extensive hyperparameter tuning, feature selection, or trying different algorithms such as ANN may lead to improvements.
  

3. **Interpretation of Features:**
   - Across all 3 models GenHlth, HighBP, BMI, HighChol, Age are crucial features, indicating their significant role in predicting diabetes.

4. **Model Deployment:**
   - Consideration should be given to the practical implications of false positives and false negatives when deploying the model for predicting diabetes.
   - Collaboration with healthcare professionals and domain experts is essential for contextualizing model outputs and ensuring responsible deployment.

5. **Thought Process/Analysis Flow**
   -The thought process and analysis flow involve addressing the imbalanced dataset using techniques like stratified splits, adjusting class weights during training, and exploring ensemble methods. The limitations and potential improvements are also discussed, including strategies for class imbalance, different evaluation metrics, hyperparameter tuning, feature selection, and trying different algorithms.

6. **Model Applications**
  -The predictive model is useful for identifying individuals at risk of diabetes. Potential applications include early intervention and targeted healthcare measures for those at risk, contributing to preventive healthcare.

### Over-sampling minority class using SMOTE

We will try to resample data to see how much improvement in performance of the model we can get.

To over-sample the the minority class, we will use SMOTE (Synthetic Minority Oversampling Technique), which analyzes each minority point's k-nearest neighbors, then generates new points by interpolating between them. This boosts minority representation in the training set, helping models learn from them and improve performance on imbalanced tasks.
"""

from imblearn.combine import SMOTEENN
from imblearn.over_sampling import SMOTE
#Sampling strategy parameter is the desired ratio of the number of samples in the minority class
# over the number of samples in the majority class after resampling.
sm = SMOTE(sampling_strategy = 1.0, random_state = 862, n_jobs = -1)

# The goal of synthetic data is to mimic real data just for training, then use real data for validation.
# Thus, we will do resampling only on the training data
X_train_resampled, y_train_resampled = sm.fit_resample(X_train1, y_train1)

# We can see that the target variable is now balanced
y_train_resampled.value_counts()

# Scale the training data
X_train_resampled_scaled = scaler.transform(X_train_resampled) ## Scaling training set

# Random Forest Classifier
rf_classifier = RandomForestClassifier(random_state=862)

rf_grid = {
    'n_estimators': [200, 300],
    'max_depth': [6, 8, 10],
    'criterion': ['gini', 'entropy']
}

start_time_rf=time.time()
grid_search_rf = GridSearchCV(rf_classifier, rf_grid, cv=5, scoring='roc_auc', n_jobs=-1)
grid_search_rf.fit(X_train_resampled_scaled, y_train_resampled)
end_time_rf = time.time()
elapsed_time_rf = end_time_rf - start_time_rf
print(f"\nTime taken for Random Forest: {elapsed_time_rf:.2f} seconds")

y_pred_rf = grid_search_rf.predict(X_test_scaled)

print("\nModel Evaluation on Test Set (Random Forest):")

best_params_rf = grid_search_rf.best_params_
print("\nBest Hyperparameters (Random Forest):", best_params_rf)

print("\nConfusion Matrix:")
plt.figure(figsize=(4, 3))
sns.heatmap(confusion_matrix(y_test1, y_pred_rf), annot=True, fmt="d", cmap="Blues", linewidths=.5, cbar=False)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Value of Diabetes')
plt.ylabel('True Value of Diabetes')
plt.show()

print("\nClassification Report:")
print(classification_report(y_test1, y_pred_rf))

feature_importance_rf = grid_search_rf.best_estimator_.feature_importances_
print("\nFeature Importance (Random Forest):")
for feature, importance in zip(X.columns, feature_importance_rf):
    print(f"{feature}: {importance:.4f}")

sorted_idx_rf = feature_importance_rf.argsort()
sorted_features_rf = X.columns[sorted_idx_rf]
sorted_importance_rf = feature_importance_rf[sorted_idx_rf]

plt.figure(figsize=(10, 6))
plt.barh(range(len(sorted_features_rf)), sorted_importance_rf, color='red',align="center")
plt.yticks(range(len(sorted_features_rf)), sorted_features_rf)
plt.xlabel("Feature Importance")
plt.title("Random Forest Feature Importance")
plt.show()

# Calculate predicted probabilities
y_prob_rf = grid_search_rf.predict_proba(X_test_scaled)[:, 1]

# Calculate ROC curve and AUC
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test1, y_prob_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='darkorange', lw=2, label='ROC curve (AUC = {:.2f})'.format(roc_auc_rf))
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Random Forest')
plt.legend(loc='lower right')
plt.show()
